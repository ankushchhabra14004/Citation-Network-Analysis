{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f63658",
   "metadata": {},
   "source": [
    "# Task 4 â€” Comparison of PageRank Algorithms and Topic-Sensitive PageRank Implementation\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook compares three PageRank variants and implements Topic-Sensitive PageRank on the citation network.\n",
    "\n",
    "### 1. Normal (Vanilla) PageRank\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "$$PR(v) = \\frac{1-d}{N} + d \\sum_{u \\in In(v)} \\frac{PR(u)}{L(u)}$$\n",
    "\n",
    "where:\n",
    "- $PR(v)$ = PageRank of page $v$\n",
    "- $In(v)$ = set of pages linking to $v$\n",
    "- $L(u)$ = number of outgoing links from $u$\n",
    "- $N$ = total number of pages\n",
    "- $d$ = damping factor (e.g., 0.85)\n",
    "\n",
    "**Key Characteristics:**\n",
    "- Models a random surfer who randomly clicks links on the web.\n",
    "- With probability $d$: follows a link from the current page.\n",
    "- With probability $(1-d)$: jumps to any page uniformly at random.\n",
    "- Treats all pages equally (no bias).\n",
    "\n",
    "**Usage:** Global importance ranking; web search engines; citation networks.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Topic-Sensitive PageRank\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "$$PR_t(v) = (1-d) \\cdot p_t(v) + d \\sum_{u \\in In(v)} \\frac{PR_t(u)}{L(u)}$$\n",
    "\n",
    "where:\n",
    "- $p_t(v)$ = topic-specific teleportation vector (non-zero only for pages related to topic $t$)\n",
    "- All other components same as Normal PageRank.\n",
    "\n",
    "**Key Characteristics:**\n",
    "- Random surfer is biased toward pages relevant to a specific topic.\n",
    "- Teleportation jumps are biased to topic-related pages.\n",
    "- With probability $d$: follows links normally.\n",
    "- With probability $(1-d)$: jumps to a random topic-related page.\n",
    "\n",
    "**Usage:** Topic-specific ranking (e.g., \"security papers\"); contextual search; topical authority.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Personalized PageRank\n",
    "\n",
    "**Mathematical Formulation:**\n",
    "$$PR_{personal}(v) = (1-d) \\cdot p_{user}(v) + d \\sum_{u \\in In(v)} \\frac{PR_{personal}(u)}{L(u)}$$\n",
    "\n",
    "where:\n",
    "- $p_{user}(v)$ = personalization vector representing user's preferences (can include browsing history, interest profile, etc.)\n",
    "- Can be fully customized per user.\n",
    "\n",
    "**Key Characteristics:**\n",
    "- Generalization of Topic-Sensitive PR.\n",
    "- Teleportation depends on individual user preferences.\n",
    "- Each user has its own PageRank vector.\n",
    "- Enables fine-grained personalization.\n",
    "\n",
    "**Usage:** Recommendation systems; personalized search results; user-specific ranking.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparison Table\n",
    "\n",
    "| Aspect | Normal PageRank | Topic-Sensitive PageRank | Personalized PageRank |\n",
    "|--------|-----------------|-------------------------|----------------------|\n",
    "| **Teleportation** | Uniform (all pages equally) | Biased to topic-related pages | Biased to user preferences |\n",
    "| **Bias** | None (global) | Topic-based | User/profile-based |\n",
    "| **Use Case** | General ranking | Topic/domain-specific ranking | Individual personalization |\n",
    "| **Complexity** | Low | Medium | Medium to High |\n",
    "| **One-time computation?** | Yes | Compute per topic | Compute per user |\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation: Topic-Sensitive PageRank\n",
    "\n",
    "Below, we implement Topic-Sensitive PageRank on the citation network for five topics: **security**, **hashing**, **streaming**, **timeseries**, and **search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f7f635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389d0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /Users/ankushchhabra/Downloads/Data Mining Assignment2/dblp_subset.json\n",
      "Read 49572 papers in 0.63s\n",
      "Built mappings for 49572 papers\n"
     ]
    }
   ],
   "source": [
    "# Load the subset file and build the citation graph\n",
    "subset_path = os.path.join(os.getcwd(), 'dblp_subset.json')\n",
    "print('Reading', subset_path)\n",
    "start = time.time()\n",
    "papers = []\n",
    "with open(subset_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            papers.append(json.loads(line))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "n = len(papers)\n",
    "print(f'Read {n} papers in {time.time()-start:.2f}s')\n",
    "\n",
    "# Build mappings\n",
    "id_to_idx = {}\n",
    "titles = []\n",
    "refs_by_id = []\n",
    "for idx, p in enumerate(papers):\n",
    "    pid = p.get('id')\n",
    "    id_to_idx[pid] = idx\n",
    "    titles.append(p.get('title', '') or '')\n",
    "    refs_by_id.append(p.get('references', []) or [])\n",
    "\n",
    "print('Built mappings for', n, 'papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad9c076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building directed graph...\n",
      "Graph built in 0.36s\n",
      "Nodes: 49572, Edges: 163309\n"
     ]
    }
   ],
   "source": [
    "# Build directed citation graph using NetworkX\n",
    "# Edge (i -> j) means paper i cites paper j\n",
    "print('Building directed graph...')\n",
    "start = time.time()\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(n))\n",
    "\n",
    "for i, refs in enumerate(refs_by_id):\n",
    "    for ref_id in refs:\n",
    "        j = id_to_idx.get(ref_id)\n",
    "        if j is not None:\n",
    "            G.add_edge(i, j)\n",
    "\n",
    "print(f'Graph built in {time.time()-start:.2f}s')\n",
    "print(f'Nodes: {G.number_of_nodes()}, Edges: {G.number_of_edges()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "785658e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"security\": 519 papers\n",
      "Topic \"hashing\": 75 papers\n",
      "Topic \"streaming\": 154 papers\n",
      "Topic \"timeseries\": 1 papers\n",
      "Topic \"search\": 1309 papers\n"
     ]
    }
   ],
   "source": [
    "# Define topics and find papers relevant to each topic\n",
    "topics = [['security'], ['hashing'], ['streaming'], ['timeseries', 'time-series'], ['search']]\n",
    "\n",
    "# For each topic, find papers whose title contains the topic word (case-insensitive)\n",
    "topic_papers = {}\n",
    "for topic in topics:\n",
    "    relevant_papers = []\n",
    "    for idx, title in enumerate(titles):\n",
    "      for t in topic:\n",
    "        if t.lower() in title.lower():\n",
    "            relevant_papers.append(idx)\n",
    "    topic_papers[topic[0]] = relevant_papers\n",
    "    print(f'Topic \"{topic}\": {len(relevant_papers)} papers')\n",
    "for i in range(len(topics)):\n",
    "    topics[i] = topics[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6175df02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defined\n"
     ]
    }
   ],
   "source": [
    "# Function to compute Topic-Sensitive PageRank\n",
    "def compute_topic_sensitive_pagerank(G, topic_nodes, alpha=0.85):\n",
    "    \"\"\"\n",
    "    Compute Topic-Sensitive PageRank for a given set of topic-relevant nodes.\n",
    "    \n",
    "    Parameters:\n",
    "    - G: NetworkX DiGraph\n",
    "    - topic_nodes: list of node indices that are relevant to the topic\n",
    "    - alpha: damping factor (default 0.85)\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of PageRank scores for all nodes\n",
    "    \"\"\"\n",
    "    # Create personalization vector\n",
    "    # Equal probability for topic nodes, zero for others\n",
    "    personalization = {}\n",
    "    n = len(G)\n",
    "    \n",
    "    if len(topic_nodes) == 0:\n",
    "        # If no topic-specific nodes, use uniform distribution\n",
    "        for node in G.nodes():\n",
    "            personalization[node] = 1.0 / n\n",
    "    else:\n",
    "        # Distribute probability equally among topic nodes\n",
    "        prob_per_topic_node = 1.0 / len(topic_nodes)\n",
    "        for node in G.nodes():\n",
    "            if node in topic_nodes:\n",
    "                personalization[node] = prob_per_topic_node\n",
    "            else:\n",
    "                personalization[node] = 0.0\n",
    "    \n",
    "    # Compute PageRank with personalization vector\n",
    "    pr = nx.pagerank(G, alpha=alpha, personalization=personalization)\n",
    "    return pr\n",
    "\n",
    "print('Function defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13acdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Topic-Sensitive PageRank for \"security\"...\n",
      "  Computed in 2.16s; topic-relevant nodes: 519\n",
      "\n",
      "Computing Topic-Sensitive PageRank for \"hashing\"...\n",
      "  Computed in 0.12s; topic-relevant nodes: 75\n",
      "\n",
      "Computing Topic-Sensitive PageRank for \"streaming\"...\n",
      "  Computed in 0.21s; topic-relevant nodes: 154\n",
      "\n",
      "Computing Topic-Sensitive PageRank for \"timeseries\"...\n",
      "  Computed in 0.10s; topic-relevant nodes: 1\n",
      "\n",
      "Computing Topic-Sensitive PageRank for \"search\"...\n",
      "  Computed in 0.38s; topic-relevant nodes: 1309\n"
     ]
    }
   ],
   "source": [
    "# Compute Topic-Sensitive PageRank for each topic\n",
    "alpha = 0.85\n",
    "results = {}\n",
    "\n",
    "for topic in topics:\n",
    "    print(f'\\nComputing Topic-Sensitive PageRank for \"{topic}\"...')\n",
    "    start = time.time()\n",
    "    topic_nodes = topic_papers[topic]\n",
    "    pr = compute_topic_sensitive_pagerank(G, topic_nodes, alpha=alpha)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    # Get top-10 papers by PageRank\n",
    "    top_k = 10\n",
    "    top_papers = sorted(pr.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "    \n",
    "    results[topic] = {\n",
    "        'pagerank': pr,\n",
    "        'top_papers': top_papers,\n",
    "        'topic_nodes': topic_nodes\n",
    "    }\n",
    "    \n",
    "    print(f'  Computed in {elapsed:.2f}s; topic-relevant nodes: {len(topic_nodes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6f7729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "TOP-10 PAPERS FOR TOPIC: SECURITY\n",
      "==========================================================================================\n",
      "S.No.  Title                                              PageRank Score       Citations \n",
      "------------------------------------------------------------------------------------------\n",
      "1      Security and Privacy Challenges in Cloud Comput... 0.00895640           33        \n",
      "2      Neutralization: new insights into the problem o... 0.00801610           21        \n",
      "3      SecureCloud: Towards a Comprehensive Security F... 0.00731781           3         \n",
      "4      Enabling Public Auditability and Data Dynamics ... 0.00675030           47        \n",
      "5      Dependable and Secure Sensor Data Storage with ... 0.00674550           3         \n",
      "6      Stackelberg vs. Nash in security games: interch... 0.00605933           8         \n",
      "7      A lattice-based approach to mashup security        0.00565877           8         \n",
      "8      Google Android: A Comprehensive Security Assess... 0.00548706           22        \n",
      "9      Permissive dynamic information flow analysis       0.00516127           6         \n",
      "10     Improving Wireless Physical Layer Security via ... 0.00513149           46        \n",
      "\n",
      "==========================================================================================\n",
      "TOP-10 PAPERS FOR TOPIC: HASHING\n",
      "==========================================================================================\n",
      "S.No.  Title                                              PageRank Score       Citations \n",
      "------------------------------------------------------------------------------------------\n",
      "1      Semi-supervised hashing for scalable image retr... 0.04883837           41        \n",
      "2      Sequential Projection Learning for Hashing with... 0.03323561           31        \n",
      "3      SPEC hashing: Similarity preserving algorithm f... 0.02229536           14        \n",
      "4      Hashing with Graphs                                0.01938876           39        \n",
      "5      Weakly-supervised hashing in kernel space          0.01879445           16        \n",
      "6      Minimal Loss Hashing for Compact Binary Codes      0.01811736           42        \n",
      "7      Hashing Algorithms for Large-Scale Learning        0.01810516           4         \n",
      "8      Self-taught hashing for fast similarity search     0.01756456           24        \n",
      "9      Supervised hashing with kernels                    0.01665899           39        \n",
      "10     b-Bit minwise hashing                              0.01511820           7         \n",
      "\n",
      "==========================================================================================\n",
      "TOP-10 PAPERS FOR TOPIC: STREAMING\n",
      "==========================================================================================\n",
      "S.No.  Title                                              PageRank Score       Citations \n",
      "------------------------------------------------------------------------------------------\n",
      "1      An evaluation of TCP-based rate-control algorit... 0.02727341           9         \n",
      "2      An experimental evaluation of rate-adaptation a... 0.01712650           31        \n",
      "3      An experimental investigation of the Akamai ada... 0.01420783           10        \n",
      "4      Watching Video over the Web: Part 1: Streaming ... 0.00958449           6         \n",
      "5      Rate adaptation for adaptive HTTP streaming        0.00855723           12        \n",
      "6      On the exact space complexity of sketching and ... 0.00716907           4         \n",
      "7      Feedback control for adaptive live video streaming 0.00690223           12        \n",
      "8      Impact of Network Dynamics on User's Video Qual... 0.00687943           3         \n",
      "9      UUSee: Large-Scale Operational On-Demand Stream... 0.00662442           8         \n",
      "10     The MPEG-DASH Standard for Multimedia Streaming... 0.00656116           8         \n",
      "\n",
      "==========================================================================================\n",
      "TOP-10 PAPERS FOR TOPIC: TIMESERIES\n",
      "==========================================================================================\n",
      "S.No.  Title                                              PageRank Score       Citations \n",
      "------------------------------------------------------------------------------------------\n",
      "1      An artificial neural network (p,d,q) model for ... 0.96298330           3         \n",
      "2      LIBSVM: A library for support vector machines      0.00370263           638       \n",
      "3      Fast and Scalable Local Kernel Machines            0.00238739           3         \n",
      "4      Factored Shapes and Appearances for Parts-based... 0.00210618           19        \n",
      "5      ClassCut for unsupervised class segmentation       0.00201927           9         \n",
      "6      The Pascal Visual Object Classes (VOC) Challenge   0.00112110           376       \n",
      "7      Object Detection with Discriminatively Trained ... 0.00093114           430       \n",
      "8      Random Walks, Markov Processes and the Multisca... 0.00032972           11        \n",
      "9      A Singular Value Thresholding Algorithm for Mat... 0.00029961           134       \n",
      "10     Fixed point and Bregman iterative methods for m... 0.00028045           59        \n",
      "\n",
      "==========================================================================================\n",
      "TOP-10 PAPERS FOR TOPIC: SEARCH\n",
      "==========================================================================================\n",
      "S.No.  Title                                              PageRank Score       Citations \n",
      "------------------------------------------------------------------------------------------\n",
      "1      LIBSVM: A library for support vector machines      0.00962269           638       \n",
      "2      Fast and Scalable Local Kernel Machines            0.00625242           3         \n",
      "3      Factored Shapes and Appearances for Parts-based... 0.00531782           19        \n",
      "4      The Pascal Visual Object Classes (VOC) Challenge   0.00505526           376       \n",
      "5      ClassCut for unsupervised class segmentation       0.00366422           9         \n",
      "6      Object Detection with Discriminatively Trained ... 0.00284729           430       \n",
      "7      Beyond DCG: user behavior as a predictor of a s... 0.00275919           11        \n",
      "8      A Theoretical and Empirical Study of Search-Bas... 0.00239307           20        \n",
      "9      Action design research                             0.00235960           9         \n",
      "10     A Dynamic Model of Sponsored Search Advertising    0.00232689           10        \n"
     ]
    }
   ],
   "source": [
    "# Report results for each topic\n",
    "for topic in topics:\n",
    "    print('\\n' + '='*90)\n",
    "    print(f'TOP-10 PAPERS FOR TOPIC: {topic.upper()}')\n",
    "    print('='*90)\n",
    "    print(f'{\"S.No.\":<6} {\"Title\":<50} {\"PageRank Score\":<20} {\"Citations\":<10}')\n",
    "    print('-'*90)\n",
    "    \n",
    "    top_papers = results[topic]['top_papers']\n",
    "    \n",
    "    for rank, (idx, pr_score) in enumerate(top_papers, start=1):\n",
    "        title = titles[idx]\n",
    "        # Truncate title if too long\n",
    "        if len(title) > 50:\n",
    "            title = title[:47] + '...'\n",
    "        \n",
    "        # Get in-degree (citation count)\n",
    "        citation_count = G.in_degree(idx)\n",
    "        \n",
    "        print(f'{rank:<6} {title:<50} {pr_score:<20.8f} {citation_count:<10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d66f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved security results to /Users/ankushchhabra/Downloads/Data Mining Assignment2/topic_sensitive_pagerank_security.csv\n",
      "Saved hashing results to /Users/ankushchhabra/Downloads/Data Mining Assignment2/topic_sensitive_pagerank_hashing.csv\n",
      "Saved streaming results to /Users/ankushchhabra/Downloads/Data Mining Assignment2/topic_sensitive_pagerank_streaming.csv\n",
      "Saved timeseries results to /Users/ankushchhabra/Downloads/Data Mining Assignment2/topic_sensitive_pagerank_timeseries.csv\n",
      "Saved search results to /Users/ankushchhabra/Downloads/Data Mining Assignment2/topic_sensitive_pagerank_search.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results to CSV files for easy reference\n",
    "import csv\n",
    "\n",
    "for topic in topics:\n",
    "    csv_path = os.path.join(os.getcwd(), f'topic_sensitive_pagerank_{topic}.csv')\n",
    "    top_papers = results[topic]['top_papers']\n",
    "    \n",
    "    with open(csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['Rank', 'Paper_Index', 'Title', 'PageRank_Score', 'Citation_Count'])\n",
    "        \n",
    "        for rank, (idx, pr_score) in enumerate(top_papers, start=1):\n",
    "            citation_count = G.in_degree(idx)\n",
    "            w.writerow([rank, idx, titles[idx], f'{pr_score:.8f}', citation_count])\n",
    "    \n",
    "    print(f'Saved {topic} results to {csv_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8673dbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "SUMMARY STATISTICS\n",
      "==========================================================================================\n",
      "\n",
      "Topic: SECURITY\n",
      "  Topic-relevant papers in collection: 519\n",
      "  Top-10 avg PageRank score: 0.00652840\n",
      "  Top-10 avg citation count: 19.70\n",
      "\n",
      "Topic: HASHING\n",
      "  Topic-relevant papers in collection: 75\n",
      "  Top-10 avg PageRank score: 0.02281168\n",
      "  Top-10 avg citation count: 25.70\n",
      "\n",
      "Topic: STREAMING\n",
      "  Topic-relevant papers in collection: 154\n",
      "  Top-10 avg PageRank score: 0.01108858\n",
      "  Top-10 avg citation count: 10.30\n",
      "\n",
      "Topic: TIMESERIES\n",
      "  Topic-relevant papers in collection: 1\n",
      "  Top-10 avg PageRank score: 0.09761608\n",
      "  Top-10 avg citation count: 168.20\n",
      "\n",
      "Topic: SEARCH\n",
      "  Topic-relevant papers in collection: 1309\n",
      "  Top-10 avg PageRank score: 0.00425985\n",
      "  Top-10 avg citation count: 152.50\n"
     ]
    }
   ],
   "source": [
    "# Summary and Statistics\n",
    "print('\\n' + '='*90)\n",
    "print('SUMMARY STATISTICS')\n",
    "print('='*90)\n",
    "\n",
    "for topic in topics:\n",
    "    top_papers = results[topic]['top_papers']\n",
    "    topic_nodes = results[topic]['topic_nodes']\n",
    "    \n",
    "    # Average PageRank for top-10\n",
    "    avg_pr = np.mean([score for _, score in top_papers])\n",
    "    \n",
    "    # Average citation count for top-10\n",
    "    avg_citations = np.mean([G.in_degree(idx) for idx, _ in top_papers])\n",
    "    \n",
    "    print(f'\\nTopic: {topic.upper()}')\n",
    "    print(f'  Topic-relevant papers in collection: {len(topic_nodes)}')\n",
    "    print(f'  Top-10 avg PageRank score: {avg_pr:.8f}')\n",
    "    print(f'  Top-10 avg citation count: {avg_citations:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4730d59",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Topic-Sensitive PageRank successfully ranks papers by their importance within specific topics:\n",
    "\n",
    "1. **Bias toward topics**: By using a personalization vector biased toward topic-relevant papers, the algorithm naturally emphasizes papers that are authorities in that specific domain.\n",
    "\n",
    "2. **Ranking changes**: Papers ranked highly in one topic may rank differently in another topic, reflecting the true structure of domain-specific citation networks.\n",
    "\n",
    "3. **Citations vs. PageRank**: Notice that papers with higher PageRank scores in a topic often (but not always) have higher citation counts. This shows PageRank captures a richer notion of importance than simple citation count.\n",
    "\n",
    "4. **Use cases**: Topic-Sensitive PageRank is valuable for:\n",
    "   - Domain-specific literature discovery\n",
    "   - Ranking papers in specialized research areas\n",
    "   - Building topic-focused recommendation systems\n",
    "   - Identifying influential papers within research communities\n",
    "\n",
    "Results have been saved to individual CSV files for each topic."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
